{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShaifaliKhulbe/Project_1/blob/main/Full_final_tweets%2Bretweets%2Bquote_tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pHctLtkbXszt"
      },
      "outputs": [],
      "source": [
        "# Import the libraries.\n",
        "import os\n",
        "import tweepy as tw\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import configparser\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read('Config_2.ini')\n",
        "\n",
        "\n",
        "# Assigning Twitter Developer API’s and Access Tokens to variables.\n",
        "api_key = config['twitter']['api_key']\n",
        "api_secret = config['twitter']['api_key_secret']\n",
        "\n",
        "access_token = config['twitter']['access_token']\n",
        "access_token_secret = config['twitter']['access_token_secret'] \n",
        "\n",
        "\n",
        "# Authenticate the API’s and Access Tokens.\n",
        "auth = tw.OAuthHandler(api_key, api_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "# Define the search words and start date as variables. \n",
        "#search_words = \"football\"\n",
        "date_since = \"2022-01-01\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def quote_tweets(name, tweet_id, tweet_url):\n",
        "\n",
        "\n",
        "  replies=[] #replies to original tweet\n",
        "  quotes=[] #tweets with true quote status\n",
        "  matching_quotes = [] #tweet\n",
        "  quote_ids = [] #tweet id of tweet being quoted\n",
        "  objects = [] #tweet metadata\n",
        "  all_tweets=[] #all tweets returned\n",
        "  for tweet in tw.Cursor(api.search,q=tweet_url).items(3000):\n",
        "    #Checks if tweet is a tweet reply to the specific tweet\n",
        "      all_tweets.append(tweet)\n",
        "      if hasattr(tweet, 'in_reply_to_status_id_str'):\n",
        "          if (tweet.in_reply_to_status_id_str==tweet_id):\n",
        "              replies.append(tweet)\n",
        "      #if hasattr(tweet, 'quoted_status'):\n",
        "      if tweet.is_quote_status == True:\n",
        "        quotes.append(tweet) #Full Tweet objects with all the meta data\n",
        "        quote_ids.append(tweet.quoted_status_id) #These should all be the exact same\n",
        "        if str(tweet_id) == str(tweet.quoted_status_id):\n",
        "          objects.append(tweet)\n",
        "          matching_quotes.append(tweet.text)\n",
        "      \n",
        "\n",
        "  return objects"
      ],
      "metadata": {
        "id": "7Ef0KNIpXzXT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources: \n",
        "\n",
        "https://colab.research.google.com/drive/1jLOCy0LdK396lTth44uTqNmV3WbaAQ4f?usp=sharing#scrollTo=2eyHQIWn2t1w"
      ],
      "metadata": {
        "id": "PmUrP5iOf0HF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_related_tweets(key_word, date_since):\n",
        "\n",
        "\n",
        "    tweet_user = []\n",
        "    tweet_time = []\n",
        "    tweet_string = []\n",
        "    tweet_location = [] \n",
        "    tweet_followers = []\n",
        "    tweet_following = []\n",
        "    tweet_like = []\n",
        "    tweet_hashtags = []\n",
        "    tweet_description = []\n",
        "    tweet_totaltweets = []\n",
        "    tweet_retweet_count = []\n",
        "    tweet_id = []\n",
        "    tweet_place = []\n",
        "    \n",
        "    \n",
        "\n",
        "    retweet_user = []\n",
        "    retweet_time = []\n",
        "    retweet_location = [] \n",
        "    retweet_followers = []\n",
        "    retweet_following = []\n",
        "    retweet_hashtags = []\n",
        "    retweet_description = []\n",
        "    retweet_string = []\n",
        "    retweet_id = []\n",
        "    retweet_place = []\n",
        "    \n",
        "    \n",
        "    quote_tweet_user = []\n",
        "    quote_tweet_time = []\n",
        "    quote_tweet_location = [] \n",
        "    quote_tweet_followers = []\n",
        "    quote_tweet_following = []\n",
        "    quote_tweet_hashtags = []\n",
        "    quote_tweet_description = []\n",
        "    quote_tweet_string = []\n",
        "    quote_tweet_id = []\n",
        "    quote_tweet_place = []\n",
        "    \n",
        "\n",
        "\n",
        "    for tweet in tqdm(tw.Cursor(api.search, lang = \"en\", q=key_word, since = date_since, count=50, tweet_mode='extended').items(50)):\n",
        "            if (not tweet.retweeted) and ('RT @' not in tweet.full_text):\n",
        "                if tweet.lang == \"en\":\n",
        "\n",
        "                    #COLLECTING INFO ON TWEETS\n",
        "\n",
        "                    tweet_user.append(tweet.user.name)\n",
        "                    tweet_time.append(tweet.created_at)\n",
        "                    tweet_string.append(tweet.full_text)\n",
        "                    tweet_location.append(tweet.user.location)\n",
        "                    tweet_place.append(tweet.place)\n",
        "                    \n",
        "                    tweet_followers.append(tweet.user.followers_count)\n",
        "                    tweet_following.append(tweet.user.friends_count)\n",
        "                    tweet_like.append(tweet.favorite_count)           \n",
        "                    tweet_id.append(tweet.id_str)\n",
        "                    tweet_description.append(tweet.user.description)\n",
        "                    tweet_totaltweets.append(tweet.user.statuses_count)\n",
        "                    tweet_retweet_count.append(tweet.retweet_count)\n",
        "\n",
        "                    #extract hashtags\n",
        "                    hashtags = tweet.entities['hashtags']\n",
        "                    hashtext = list()\n",
        "                    for i in range(0, len(hashtags)):\n",
        "                      hashtext.append(hashtags[i]['text'])\n",
        "                    tweet_hashtags.append(hashtext)\n",
        "\n",
        "\n",
        "                    #COLLECTING INFO ON RETWEETS\n",
        "\n",
        "                    retweeters = api.retweets(tweet.id_str)\n",
        "\n",
        "                    for retweet in retweeters:                              \n",
        "                      \n",
        "                      #original tweet's id which has been retweeted\n",
        "                      retweet_id.append(tweet.id_str)\n",
        "                      retweet_string.append(retweet.text)              \n",
        "                      retweet_user.append(retweet.user.name)\n",
        "                      retweet_time.append(retweet.created_at)\n",
        "                      retweet_description.append(retweet.user.description)\n",
        "                      retweet_location.append(retweet.user.location)\n",
        "                      retweet_followers.append(retweet.user.followers_count)\n",
        "                      retweet_following.append(retweet.user.friends_count)\n",
        "                      retweet_place.append(retweet.place)\n",
        "                      \n",
        "                      \n",
        "                      \n",
        "                      #extract hashtags\n",
        "                      hashtags = retweet.entities['hashtags']\n",
        "                      hashtext = list()\n",
        "                      for i in range(0, len(hashtags)):\n",
        "                        hashtext.append(hashtags[i]['text'])\n",
        "                      retweet_hashtags.append(hashtext)\n",
        "\n",
        "\n",
        "                    #COLLECTING INFO ON QUOTE TWEETS\n",
        "\n",
        "                    tweet_url = f\"https://twitter.com/{tweet.user.screen_name}/status/{tweet.id}\"\n",
        "\n",
        "\n",
        "                    objects = quote_tweets(tweet.user.name , tweet.id_str, tweet_url)\n",
        "\n",
        "                    print(\"Number of quote tweets: \", len(objects))\n",
        "\n",
        "                    for qtweet in objects:\n",
        "                        \n",
        "                      print(\"TWEET.ID: \" , tweet.id_str)\n",
        "                      print(\"TWEET.TEXT: \", tweet.text)\n",
        "                      print(qtweet.text)\n",
        "                      print(qtweet.created_at)\n",
        "\n",
        "    \n",
        "                      quote_tweet_id.append(tweet.id_str)\n",
        "                      quote_tweet_string.append(qtweet.full_text)              \n",
        "                      quote_tweet_user.append(qtweet.user.name)\n",
        "                      quote_tweet_time.append(qtweet.created_at)\n",
        "                      quote_tweet_description.append(qtweet.user.description)\n",
        "                      quote_tweet_location.append(qtweet.user.location)\n",
        "                      quote_tweet_followers.append(qtweet.user.followers_count)\n",
        "                      quote_tweet_following.append(qtweet.user.friends_count)\n",
        "                      quote_tweet_place.append(qtweet.place.country)\n",
        "                      \n",
        "                      \n",
        "                      \n",
        "                      #extract hashtags\n",
        "                      hashtags = qtweet.entities['hashtags']\n",
        "                      hashtext = list()\n",
        "                      for i in range(0, len(hashtags)):\n",
        "                        hashtext.append(hashtags[i]['text'])\n",
        "                      quote_tweet_hashtags.append(hashtext)\n",
        "\n",
        "  \n",
        "    #DATAFRAME TO STORE TWEET INFORMATION            \n",
        "    \n",
        "    df_tweets = pd.DataFrame({'tweet_id': tweet_id, 'user_name':tweet_user, 'user_description': tweet_description, \"total_user_tweets\": tweet_totaltweets, 'time': tweet_time, 'tweet': tweet_string, 'location' : tweet_location, 'followers': tweet_followers,\n",
        "          'following': tweet_following,'hashtags': tweet_hashtags,'likes': tweet_like, 'number_of_retweets': tweet_retweet_count, \n",
        "          'tweet_place' : tweet_place })\n",
        "    df_tweets.to_csv(f\"{key_word}.csv\")\n",
        "\n",
        "    #DATAFRAME TO STORE RETWEET INFORMATION PER TWEET\n",
        "\n",
        "    df_retweets = pd.DataFrame({'retweet_id' : retweet_id, 'retweet_text' : retweet_string, 'name' :retweet_user, 'time': retweet_time,'location' : retweet_location, 'followers': retweet_followers,\n",
        "                        'following': retweet_following, 'hashtags': retweet_hashtags,  'retweet_place' : retweet_place})    \n",
        "    df_retweets.to_csv(f\"{key_word}_retweets.csv\") \n",
        "\n",
        "    #DATAFRAME TO STORE QUOTE_TWEET INFORMATION PER TWEET \n",
        "  \n",
        "    df_qtweets = pd.DataFrame({'quote_tweet_id' : quote_tweet_id, 'quote_tweet_text' : quote_tweet_string, 'name':quote_tweet_user, 'time': quote_tweet_time,'location' : quote_tweet_location, 'followers': quote_tweet_followers,\n",
        "                  'following': quote_tweet_following, 'hashtags': quote_tweet_hashtags, 'quote_tweet_place' : quote_tweet_place\n",
        "                      })    \n",
        "    df_qtweets.to_csv(f\"{key_word}_quote_tweets.csv\")\n",
        "\n",
        "    \n",
        "    return df_tweets, df_retweets, df_qtweets\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "SELA9i7QZrsp"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords_list = []\n",
        "\n",
        "file_keywords = pd.read_csv (r'/content/keywords.csv')\n",
        "for i in range(0, len(file_keywords)):\n",
        "  keyword = file_keywords.iloc[i, 1]\n",
        "  keywords_list.append(keyword.lower())\n"
      ],
      "metadata": {
        "id": "sKzzmZVRKZyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for keyword in tqdm(keywords_list): \n",
        "  # Call the function to get related tweets in csv files\n",
        "  df_tweets, df_retweets, df_qtweets = get_related_tweets(keyword, date_since)"
      ],
      "metadata": {
        "id": "qseKSN8F0bKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(keywords_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwPBUbbOKLYF",
        "outputId": "7088ef6b-7b20-415f-f09b-ad2965d00737"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['culture', 'ai', 'artificialintelligence', 'machinelearning', 'deeplearning', 'art', 'arts', 'music', 'cryptocurrency', 'olympics', 'funny', 'crowdfunding', 'influencermarketing', 'opioid', 'healthinsurance', 'photography', 'vegan', 'ethereum', 'bitcoin', 'gold', 'movies', 'running', 'cryptocurrencies', 'java', 'python', 'blockchain', 'datascience', 'fintech', 'science', 'fitnessfacebook', 'youtube', 'amazon', 'weather', 'google', 'gmail', 'instagram', 'translate', 'ipl', 'wordle', 'bbcnews', 'flipkart', 'startbucks', 'cricket', 'fifaworldcup', 'qatar2022', 'tiktok', 'argentina', 'messi', 'worldcup', 'givingtuesday', 'christmas', 'fifaworldcup', 'elections', 'bollywood', 'beinghuman', 'elonmusk', 'dogecoin', 'pokemon', 'nintendoswitch', 'spirituality', 'soul', 'aliens', 'earth', 'water', 'flood', 'naturaldisaster', 'religion', 'god', 'satan', 'entrepreneur', 'hinduism', 'islam', 'christinity', 'jew', 'buddhism', 'home', 'house', 'realestate', 'truth', 'energy', 'racism', 'gratitude', 'wisdom', 'yoga', 'dance', 'football', 'liar', 'famous', 'school', 'college', 'university', 'research', 'billgates', 'elonmusk', 'modi', 'putin', 'russia', 'china', 'india', 'belgium']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "95IuWWm7KLbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYHHhOX11lZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4hnVBdW81lbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kaj1A7uY1ldy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JlmLTcaZ1lg_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}